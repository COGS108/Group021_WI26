{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Lincoln Wirschem: Conceptualization, Writing Background - original draft\n",
    "- Ricardo Hernandez: Data Collection/Ethics\n",
    "- Vedant Patel: Writing - review & editing\n",
    "- Aleksey Dykhno: Planning\n",
    "- Yash Goel: Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 2015 to 2023 (excluding the shortened 2020 season), how do early-season team run differential per game, on-base percentage plus slugging (OPS), and pitching ERA measured over the first 81 games (first half) relate to MLB playoff qualification, and how does the predictive power of these metrics, as measured by classification performance, change by the end of the regular season?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the existence of Major League Baseball, there have been increased investments into franchises to create more revenue by having more competitive teams. MLB owners often invest money into star players to bring attention and fans to their team, which makes them profit and repeats this cycle. One of the main metrics to record how well a team is doing, is if they are able to make the League’s playoffs, which only a select group of teams make. All with the ultimate goal of winning the World Series Championship.\n",
    "\n",
    "To measure the predictability of a team’s chances of making the playoffs, there are projections created by a mixture of team statistics intertwined with individual players’ statistics. Throughout Prior Work that we found, each publication of the research started with defining what the Benchmarks for the data analysis were <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2), and what features to create the prediction from. The most common ones were from the Final Project at Stanford, created by Randy Jia, Chris Wong, and David Zeng, where they selected BA, RBI, OBP, ERA, H, E, and Win% for each team to be the metrics they used in their predictive model. They found that these metrics were representative of the state of each MLB team within their respective time frame.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)\n",
    "\n",
    "Dr. Gregory Wood and David Marmor created an inferential model about correlations between teams' statistics during the regular season versus team statistics during the playoff season. <a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) In this, they compared stats like a team’s regular season wins versus their playoff wins, playoff ERA vs. playoff wins, playoff net runs vs playoff wins, and playoff allowed runs vs playoff wins. In these comparisons, they found an intriguing conclusion that the correlation coefficient for these datasets was extremely close to 0, meaning they had no linear correlation for teams. Which meant that they came to the conclusion that their stats for playoff teams were not directly correlated, and that a randomness factor comes into play for the playoffs. Although this type of analysis is similar to what we will do in this project, it is not directly tied, because this research group only used data from the playoffs, comparing it also to the playoffs, whereas we will use early regular season data and compare it to how the playoff entries turned out. Not using a predictive model, but instead an analysis of whether there was a correlation.\n",
    "\n",
    "This was similar to another reference that we found, which is a research article created by Stanley Rothman, where he created a predictive model of how many wins a team would get depending on the Runs Allowed and Runs Scored, using a linear regression. <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1)They concluded that their two predictive models “both were effective in predicting the actual win totals for the 2013 MLB season.” They then recreated the same experiment through the NBA and NFL as well, but with Points Scored versus Points Against. This research article was helpful to see how other research groups wrangled their data, and what analysis they took from it.\n",
    "\n",
    "The most useful reference that we found that we think is most applicable to our project, is a Playoff Prediction section of the Fangraphs website.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) This part of the website/data gives us a metric that Fangraphs uses to calculate the playoff odds for each individual team after each game is played (aka the calulation is updated by date). This is the most useful reference for us because it allows us to have a measurable metric to compare at the beginning and end of our time interval, to compare our inferences to.\n",
    "\n",
    "Statistic Legend:\n",
    "-  Batting Average = Hits / At Bats\n",
    "- Home Runs = 4 Bases, an RBI and a Run for this batter\n",
    "- RBIs = Runs earned by a Hit or a Sacrifice Fly\n",
    "- Runs scored = Total times a player crosses home plate\n",
    "- Stolen Bases = Runner advancing from base to base (not including home plate to first base)\n",
    "- Wins = Team Wins\n",
    "- ERA = Earned Run Average, Earned Runs / Innings Pitched\n",
    "- WHIP = Walks + Hits per Innings Pitched\n",
    "- OBP = On Base Percentage, counts if batter gets on base (aka Hits, Hit by Pitch, or\n",
    "- Strikeouts = Swinging strikeouts or Looking Strikeouts\n",
    "- Saves = Pitcher Save, finishes a game for the winning team under specific conditions\n",
    "\n",
    "\n",
    "\n",
    "Citation:\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Rothman, Stanley. “A New Formula to Predict a Team’s Winning Percentage.” Society for American Baseball Research, 31 Jan. 2024, https://sabr.org/journal/article/a-new-formula-to-predict-a-teams-winning-percentage/\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Jia, Randy, et al. Predicting the Major League Baseball Season, https://cs229.stanford.edu/proj2013/JiaWongZeng-PredictingTheMajorLeagueBaseballSeason.pdf Accessed 3 Feb. 2026. \n",
    "3. <a name=\"cite_note-2\"></a> [^](#cite_ref-3) “MLB Playoff Odds.” FanGraphs Baseball, www.fangraphs.com/standings/playoff-odds/fg/div?date=2024-03-27. Accessed 3 Feb. 2026. \n",
    "4. <a name=\"cite_note-2\"></a> [^](#cite_ref-4)  Dr. Gregory Wood and David Marmor. “Predicting the Playoffs.” Fangraphs Community Blog, 30 Aug. 2017, https://community.fangraphs.com/predicting-the-playoffs/. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that MLB teams with a higher run differential per game and OPS, along with lower pitching ERA over the first 81 games, will have a higher chance of qualifying for the playoffs. \n",
    "\n",
    "Among these metrics, we expect the run differential to be the strongest indicator of success (defined as qualifying for the playoffs), as it reflects overall team performance by incorporating both offensive and defensive contributions, while OPS and ERA capture specialized aspects of performance. We further hypothesize that the predictive strength of all three metrics will increase by the end of the regular season as team performance stabilizes and early-season variability decreases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "1. **The Ideal Dataset**\n",
    "   1. The ideal dataset would include information on every factor that goes into how well a team is doing. Some examples include:\n",
    "        - Batting average\n",
    "        - Home runs\n",
    "        - RBIs\n",
    "        - Runs scored\n",
    "        - Stolen Bases\n",
    "        - Wins\n",
    "        - ERA\n",
    "        - WHIP\n",
    "        - Strikeouts\n",
    "        - Saves\n",
    "        - On Base Percentage\n",
    "   1. There is much more data and statistics for baseball teams and players. This is the dataset we would want because it gives us the best idea of how teams are doing and we can compare performances across the period of time that the season takes place. \n",
    "\n",
    "\n",
    "   3. We would need 81 games of data, from each season collected (2015-2023 minus 2020 shortened season), from each team, to form a trend throughout the course of the games in the season. We would analyze the starts by looking at the first 81 and the metrics prescribed. Then we’ll continue observing how thos games relate to their playoff probabilities. Comparing the observations we made from the start to the finish. Checking big milestones (halfway) in the season to see if there was a trend upward, downward or other.\n",
    "\n",
    "  \n",
    "      \n",
    "   5. The data would be collected from Fangraphs. This is a baseball website that offers deep statistical analysis on performance. We will use a Python API. Using the pybaseball package, which already exists.\n",
    "\n",
    "   6. The data would be stored into graphs/dataframes so we can compare across the time periods described in the Research Question.\n",
    "  \n",
    "   \n",
    "2. **Dataset**\n",
    "   1. https://www.fangraphs.com/leaders.aspx We don’t need to ask permission. Only if it is used commercially. We will choose filters and download as CSV. The important variables would be batting metrics, pitching metrics, and Wins above replacement.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: The players opt-in when signing with an MLB franchise, which is part of the MLB organization\n",
    "\n",
    " - [X] **A.2 Collection bias**: There are possible biases that occur from schedule strength, rule changes, playoff format changes, injuries, etc.. We compare across seasons and exclude 2020 to counter these. \n",
    " - [X] **A.3 Limit PII exposure**: When MLB players sign for their teams, they sign to be a part of the MLB rules, which includes rules of data collection.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: We will avoid using our model to make claims about players or individuals, since our analysis is team-level. We will also be careful about over-interpreting predictions because unmeasured factors like injuries, payroll, roster changes, and strength of schedule can affect outcomes. We will reduce misuse by clearly stating limitations and framing results as predictive, not causal.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: It is public and non-sensitive data. We stored it in the project repo with basic access control.\n",
    " - [X] **B.2 Right to be forgotten**:  Not applicable since no personal data is collected.\n",
    " - [X] **B.3 Data retention plan**: We would keep only what’s needed for the project and remove the features that are unnecessary along with the years we excluded. We won’t do unnecessary raw pulls.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: We will check our assumptions using baseball analytics sources and basic sanity checks.  \n",
    " - [X] **C.2 Dataset bias**: There aren't any biases because the data collected, is collected uniformly, throughout the whole league, and for every game played.\n",
    " - [X] **C.3 Honest representation**: We will report results honestly and avoid cherry-picking seasons or graphs.  \n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: We will only analyze team-level data and will not include any personal or identifying information. \n",
    " - [X] **C.5 Auditability**: Our code and workflow will be reproducible so others can rerun the same analysis.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Our features are performance stats, not proxies for protected traits.  \n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Fairness across protected groups is not directly relevant here, but we can still check if the model performs differently across leagues or divisions.\n",
    " - [X] **D.3 Metric selection**: We will use evaluation metrics like AUC and F1 so we do not rely only on accuracy.  \n",
    " - [X] **D.4 Explainability**: We will start with an interpretable model and explain how each metric affects playoff probability.\n",
    " - [X] **D.5 Communicate limitations**: We will clearly state limitations and avoid claiming the model proves causation.  \n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: If this were deployed, we would re-evaluate performance each season and after major league changes.  \n",
    " - [X] **E.2 Redress**: We would include clear disclaimers and review mistakes to improve the model over time.  \n",
    " - [X] **E.3 Roll back**: We would keep versions of the model so we can roll back if a new version performs worse.\n",
    " - [X] **E.4 Unintended use**: We will warn against unintended use, like treating predictions as guarantees or using them for gambling decisions. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Communication**\n",
    "\n",
    "Our primary method of communication will be  iMessage and Discord, with Gmail used as a backup.\n",
    "\n",
    "Team members are expected to respond to messages promptly if major work needs to be done on their part and deadlines are near, and team members should be notified of updates on the work that needs to be completed.\n",
    "The team will meet usually once per week on Mondays, meeting virtually or in-person, depending on what was discussed in the team group chat  to discuss progress, upcoming deadlines, and problems that have caused members to be “stuck”.\n",
    "\n",
    "**Collaboration & Decision-Making**\n",
    "\n",
    "We agree to maintain a respectful communication tone.\n",
    "\n",
    "Decisions will be made through a majority vote.\n",
    "\n",
    "If a team member disagrees with a decision, they are encouraged to voice their concerns and reason with the rest of the group as to why they think that way so all perspectives are considered before moving forward.\n",
    "\n",
    "**Work Distribution & Accountability**\n",
    "\n",
    "Tasks will be divided  based on strengths with rotation, and responsibilities will be tracked through Github and oral communication.\n",
    "All team members are expected to contribute to data exploration, analysis, coding, writing, and editing, even if they take lead roles in specific areas.\n",
    "If a team member anticipates difficulty meeting a deadline, they will notify the group at least 2 days in advance so the team can adjust responsibilities as needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/4 (Wed)  |  11:00 AM | Review COGS 108 project expectations and rubric; brainstorm possible topics and questions  | Finalize communication method; select final project topic; define research question and scope; assign background research tasks | \n",
    "| 2/12 (Thurs) |  3:15 PM |  Conduct background research; gather relevant literature | Synthesize prior work; refine hypothesis; identify variables and controls; discuss ideal dataset and ethical considerations | \n",
    "| 2/17 (Mon)| 5:30 PM  | Search for and evaluate potential datasets; begin proposal drafting  | Finalize dataset choice; discuss data limitations; refine methods; assign roles for wrangling, EDA, and analysis |\n",
    "| 2/24 (Mon) | 5:30 PM  | Import and clean data; complete initial data wrangling | Review data quality; address missing values and inconsistencies; finalize EDA plan  |\n",
    "| 3/3 (Mon)| 5:30 PM  | Complete EDA and preliminary visualizations | Interpret EDA results; refine analysis approach; identify potential modeling or statistical methods |\n",
    "| 3/10 (Mon) | 5:30 PM  | Perform full analysis; draft results and discussion sections | Review analysis outputs; refine visualizations; discuss limitations and ethical implications |\n",
    "| 3/17 (Mon)  | 5:30 PM  | Complete full project draft; finalize figures, documentation and complete the final VIDEO | Final peer review; polish writing; ensure reproducibility and readiness for submission | \n",
    "| 3/18 (Tue)  | Before 11:59 PM  | NA | Submit Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
