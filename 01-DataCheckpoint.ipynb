{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Lincoln Wirschem: Conceptualization, Writing Background - original draft\n",
    "- Ricardo Hernandez: Data Collection/Ethics\n",
    "- Vedant Patel: Writing - review & editing\n",
    "- Aleksey Dykhno: Planning\n",
    "- Yash Goel: Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 2015 to 2023 (excluding the shortened 2020 season), which full-season team statistics - spanning offensive metrics (such as OPS, run differential, HR, and RBI), pitching metrics (such as ERA and WHIP), and win-loss record - are the strongest indicators of MLB playoff qualification, as measured by their predictive power in a classification model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the existence of Major League Baseball, there have been increased investments into franchises to create more revenue by having more competitive teams. MLB owners often invest money into star players to bring attention and fans to their team, which makes them profit and repeats this cycle. One of the main metrics to record how well a team is doing, is if they are able to make the League's playoffs, which only a select group of teams make. All with the ultimate goal of winning the World Series Championship.\n",
    "\n",
    "A key question in baseball analytics is: which regular-season statistics best predict whether a team reaches the postseason? Understanding which metrics most strongly separate playoff teams from non-playoff teams can inform front office decisions, player acquisition strategies, and fan expectations. To answer this, we analyze full-season team-level statistics across multiple seasons and evaluate their predictive power as indicators of playoff qualification.\n",
    "\n",
    "Prior work that we found each began with defining what the benchmarks for the data analysis were <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2), and what features to create the prediction from. The most common ones were from the Final Project at Stanford, created by Randy Jia, Chris Wong, and David Zeng, where they selected BA, RBI, OBP, ERA, H, E, and Win% for each team to be the metrics they used in their predictive model. They found that these metrics were representative of the state of each MLB team within their respective time frame, lending support to the idea that a well-chosen set of full-season statistics can reliably classify playoff teams.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2)\n",
    "\n",
    "Dr. Gregory Wood and David Marmor created an inferential model about correlations between teams' regular-season statistics versus their performance during the playoff season. <a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) They found that the correlation coefficient for regular-season statistics versus playoff outcomes was extremely close to 0, suggesting that the randomness of a short playoff series makes playoff performance hard to predict from regular season stats. This is directly relevant to our project: rather than trying to predict playoff performance, we focus on the more tractable question of predicting playoff *qualification*, which is determined by the full 162-game regular season where the large sample size reduces randomness.\n",
    "\n",
    "This was similar to another reference that we found, a research article by Stanley Rothman, where he created a predictive model of how many wins a team would get depending on Runs Allowed and Runs Scored, using a linear regression. <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) They concluded that their two predictive models \"both were effective in predicting the actual win totals for the 2013 MLB season,\" reinforcing the predictive value of run-based metrics at the team level.\n",
    "\n",
    "The most useful reference that we found is the Playoff Prediction section of the Fangraphs website.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) Fangraphs calculates the playoff odds for each team after each game is played, blending team statistics with remaining schedule. This is useful context for our work because it confirms that full-season statistics are strong enough inputs to generate meaningful playoff probability estimates — which is the same assumption underlying our classification approach.\n",
    "\n",
    "Statistic Legend:\n",
    "-  Batting Average = Hits / At Bats\n",
    "- Home Runs = 4 Bases, an RBI and a Run for this batter\n",
    "- RBIs = Runs earned by a Hit or a Sacrifice Fly\n",
    "- Runs scored = Total times a player crosses home plate\n",
    "- Stolen Bases = Runner advancing from base to base (not including home plate to first base)\n",
    "- Wins = Team Wins\n",
    "- ERA = Earned Run Average, Earned Runs / Innings Pitched\n",
    "- WHIP = Walks + Hits per Innings Pitched\n",
    "- OBP = On Base Percentage, counts if batter gets on base (aka Hits, Hit by Pitch, or\n",
    "- Strikeouts = Swinging strikeouts or Looking Strikeouts\n",
    "- Saves = Pitcher Save, finishes a game for the winning team under specific conditions\n",
    "\n",
    "\n",
    "\n",
    "Citation:\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Rothman, Stanley. \"A New Formula to Predict a Team's Winning Percentage.\" Society for American Baseball Research, 31 Jan. 2024, https://sabr.org/journal/article/a-new-formula-to-predict-a-teams-winning-percentage/\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Jia, Randy, et al. Predicting the Major League Baseball Season, https://cs229.stanford.edu/proj2013/JiaWongZeng-PredictingTheMajorLeagueBaseballSeason.pdf Accessed 3 Feb. 2026. \n",
    "3. <a name=\"cite_note-2\"></a> [^](#cite_ref-3) \"MLB Playoff Odds.\" FanGraphs Baseball, www.fangraphs.com/standings/playoff-odds/fg/div?date=2024-03-27. Accessed 3 Feb. 2026. \n",
    "4. <a name=\"cite_note-2\"></a> [^](#cite_ref-4)  Dr. Gregory Wood and David Marmor. \"Predicting the Playoffs.\" Fangraphs Community Blog, 30 Aug. 2017, https://community.fangraphs.com/predicting-the-playoffs/. \n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that full-season run differential per game will be the strongest indicator of MLB playoff qualification, as it captures both offensive production and pitching/defensive effectiveness in one metric. Teams with a positive run differential are likely winning more games and therefore more likely to reach the postseason.\n",
    "\n",
    "Among offensive metrics, we expect OPS to be a stronger predictor than batting average alone, since it better captures a team's ability to both reach base and hit for power. On the pitching side, we expect ERA to be a stronger predictor than WHIP, as it directly measures the runs a team allows rather than a rate of baserunners.\n",
    "\n",
    "Overall, we hypothesize that a combination of run differential, OPS, ERA, and team win total will together provide strong classification performance for predicting playoff qualification, with run differential contributing the most predictive weight."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "## 1. The Ideal Dataset\n",
    "\n",
    "A. The ideal dataset would include comprehensive team-level performance statistics for all MLB teams across multiple seasons. It would contain both offensive and pitching metrics that influence team success and playoff probability.\n",
    "\n",
    "##### Key variables would include:\n",
    "\n",
    "- Offensive Metrics\n",
    "\n",
    "- Batting Average (AVG)\n",
    "\n",
    "- On-Base Percentage (OBP)\n",
    "\n",
    "- Slugging Percentage (SLG)\n",
    "\n",
    "- On-Base Plus Slugging (OPS)\n",
    "\n",
    "- Home Runs (HR)\n",
    "\n",
    "- Runs Batted In (RBI)\n",
    "\n",
    "- Runs Scored (R)\n",
    "\n",
    "- Stolen Bases (SB)\n",
    "\n",
    "- Pitching Metrics\n",
    "\n",
    "- Earned Run Average (ERA)\n",
    "\n",
    "- Walks + Hits per Inning Pitched (WHIP)\n",
    "\n",
    "- Strikeouts (SO)\n",
    "\n",
    "- Saves (SV)\n",
    "\n",
    "- Advanced Metrics\n",
    "\n",
    "- Wins Above Replacement (WAR)\n",
    "\n",
    "- Team run differential\n",
    "\n",
    "- Playoff probability (if available)\n",
    "\n",
    "B. The ideal dataset would have observations from every single team (30 teams) for each season necessary (2015–2023 not including 2020 shortened season) to extract full-season team statistics. Meaning we should have around 240 different observations for these teams.\n",
    "\n",
    "C. To get the ideal data, it must be scraped from online, directly downloadable, or collected directly from an API. We would have to search for the data by year, and collect all the team data for that specific season, and then eventually wrangle it to combine the season team datasets together.\n",
    "\n",
    "D. This data would be organized into .csv files, where we would first separate the team pitching statistics from the team batting statistics. Then these datasets could be combined only keeping what is necessary for the EDA later down the line.\n",
    "\n",
    "\n",
    "### 2. Our Dataset\n",
    "\n",
    "The data will be collected from FanGraphs, which can be viewed from the website: https://www.fangraphs.com/leaders.aspx\n",
    "\n",
    "No permission is required for academic, non-commercial use.\n",
    "\n",
    "We will use the Python package pybaseball which is a Python API wrapper for baseball data sources including FanGraphs, which allows us to programmatically retrieve team-level statistics. The data can be downloaded and collected directly into CSV files using the functions given in the package.\n",
    "\n",
    "Data Size: \n",
    "\n",
    "We are using team-level data from the 2015–2023 MLB seasons, excluding 2020 due to the shortened season, which gives us 8 years worth of data, and since there are 30 MLB teams in these seasons, we have 240 different actual observations. With the pitching data, there was 390 different variables/statistics tracked for each team, and for hitting data it was 319 different variables. This is too large for what we need, so we are wrangling it to be smaller and only for necessary information.\n",
    "\n",
    "For each team, we will extract statistics from the entire season, and then using these most important variables, craft a smaller dataframe using Pandas to explore the data analysis down the line. After the data is cleaned and organized by team and season, we will visualize our data using graphs (bar charts, scatterplots, correlation heatmaps).\n",
    "\n",
    "Most Important Variables Used:\n",
    "Batting metrics (AVG, OBP, OPS, HR, R, RBI), \n",
    "Pitching metrics (ERA, WHIP, SO, SV), \n",
    "Wins (W), \n",
    "Wins Above Replacement (WAR)...to be continued if necessary\n",
    "\n",
    "Drawback of Dataset: This dataset does not include whether a team made it to the playoffs that year or not, so our main task for creating another dataframe would be to grab the playoff information and put it into a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "#datafiles = [\n",
    "#    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "#    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "#]\n",
    "\n",
    "#get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking to see if you have pybaseball installed, and if not it will install\n",
    "# using this try catch, it doesn't show the terminal output which was long\n",
    "try:\n",
    "    import pybaseball\n",
    "except ImportError:\n",
    "    !pip install pybaseball\n",
    "    import pybaseball\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybaseball import team_batting, team_pitching, standings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MLB Full-Season DATA Collection\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Collecting Batting Data\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fetching 2015 batting data... (30 teams)\n",
      "Fetching 2016 batting data... (30 teams)\n",
      "Fetching 2017 batting data... (30 teams)\n",
      "Fetching 2018 batting data... (30 teams)\n",
      "Fetching 2019 batting data... (30 teams)\n",
      "Fetching 2021 batting data... (30 teams)\n",
      "Fetching 2022 batting data... (30 teams)\n",
      "Fetching 2023 batting data... (30 teams)\n",
      "\n",
      "Total batting observations: 240\n",
      "  Expected: 240 observations\n",
      "319\n",
      "Saved to: data/00-raw/batting_full_season.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"+\"*80)\n",
    "print(\"MLB Full-Season DATA Collection\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Define seasons (excluding 2020 shortened season), and only the seasons of our hypothesis\n",
    "seasons = [2015, 2016, 2017, 2018, 2019, 2021, 2022, 2023]\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#COLLECT Batting DATA\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "print(\"Collecting Batting Data\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "batting_dfs = []\n",
    "\n",
    "#going through each year for the seasons we are using\n",
    "for year in seasons:\n",
    "    print(f\"Fetching {year} batting data...\", end=' ')\n",
    "    try:\n",
    "        batting = team_batting(year)\n",
    "        batting['Season'] = year\n",
    "        batting_dfs.append(batting)\n",
    "        print(f\"({len(batting)} teams)\")\n",
    "        \n",
    "    #Tell us our error if something messes up\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Combine all the years' data\n",
    "batting_all = pd.concat(batting_dfs, ignore_index=True) if batting_dfs else pd.DataFrame()\n",
    "\n",
    "#confirm our total batting observations to be correct:240 compared with the expected\n",
    "print(f\"\\nTotal batting observations: {len(batting_all)}\")\n",
    "print(f\"  Expected: {len(seasons) * 30} observations\")\n",
    "\n",
    "\n",
    "# Save raw batting data\n",
    "if not batting_all.empty:\n",
    "    batting_all.to_csv('data/00-raw/batting_full_season.csv', index=False)\n",
    "    #confirm that it saves to the correct spot in the folders\n",
    "    print(\"Saved to: data/00-raw/batting_full_season.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Collecting Pitching Data\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fetching 2015 pitching data... (30 teams)\n",
      "Fetching 2016 pitching data... (30 teams)\n",
      "Fetching 2017 pitching data... (30 teams)\n",
      "Fetching 2018 pitching data... (30 teams)\n",
      "Fetching 2019 pitching data... (30 teams)\n",
      "Fetching 2021 pitching data... (30 teams)\n",
      "Fetching 2022 pitching data... (30 teams)\n",
      "Fetching 2023 pitching data... (30 teams)\n",
      "\n",
      "Total pitching observations: 240\n",
      "  Expected: 240 observations\n",
      "Saved to: data/00-raw/pitching_full_season.csv\n"
     ]
    }
   ],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#COLLECT Pitching DATA\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Collecting Pitching Data\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "pitching_dfs = []\n",
    "\n",
    "#going through each year for the seasons we are using\n",
    "for year in seasons:\n",
    "    #telling you (via printing) which season is being fetched from the Import\n",
    "    print(f\"Fetching {year} pitching data...\", end=' ')\n",
    "    try:\n",
    "        pitching = team_pitching(year)\n",
    "        pitching['Season'] = year\n",
    "        pitching_dfs.append(pitching)\n",
    "        print(f\"({len(pitching)} teams)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Combine all years of data with concat\n",
    "pitching_all = pd.concat(pitching_dfs, ignore_index=True) if pitching_dfs else pd.DataFrame()\n",
    "\n",
    "#confirm the correct amount of pitching observations: 240 with the expected amount\n",
    "print(f\"\\nTotal pitching observations: {len(pitching_all)}\")\n",
    "print(f\"  Expected: {len(seasons) * 30} observations\")\n",
    "\n",
    "# Save raw pitching data\n",
    "if not pitching_all.empty:\n",
    "    pitching_all.to_csv('data/00-raw/pitching_full_season.csv', index=False)\n",
    "    print(\"Saved to: data/00-raw/pitching_full_season.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playoff Qualification DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Creating Playoff Qualification Data\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "2015: 10 playoff teams\n",
      "2016: 10 playoff teams\n",
      "2017: 10 playoff teams\n",
      "2018: 10 playoff teams\n",
      "2019: 10 playoff teams\n",
      "2021: 10 playoff teams\n",
      "2022: 12 playoff teams\n",
      "2023: 12 playoff teams\n",
      "\n",
      "Total observations: 240\n",
      "Total playoff qualifications: 84\n",
      "Saved to: data/00-raw/standings.csv\n"
     ]
    }
   ],
   "source": [
    "#Playoff Qualification DATA \n",
    "\n",
    "# Due to issues with importing of standings data from PyBaseball\n",
    "# # The design of this function is partially\n",
    "#generated by Claude from the prompt \"Help me find a way to store if \n",
    "# teams from 2015-2023 made the playoffs in order, inside a .csv\"\n",
    "\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Creating Playoff Qualification Data\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Manual list of playoff teams because dealing with the imported standings data was a pain in the butt\n",
    "PLAYOFF_TEAMS = {\n",
    "    2015: ['NYM', 'LAD', 'STL', 'PIT', 'CHC', 'KCR', 'TOR', 'TEX', 'NYY', 'HOU'],\n",
    "    2016: ['CHC', 'WSN', 'LAD', 'NYM', 'SFG', 'CLE', 'TEX', 'BOS', 'TOR', 'BAL'],\n",
    "    2017: ['LAD', 'WSN', 'CHC', 'ARI', 'COL', 'HOU', 'CLE', 'BOS', 'NYY', 'MIN'],\n",
    "    2018: ['LAD', 'ATL', 'MIL', 'CHC', 'COL', 'BOS', 'HOU', 'CLE', 'NYY', 'OAK'],\n",
    "    2019: ['LAD', 'ATL', 'STL', 'WSN', 'MIL', 'HOU', 'NYY', 'MIN', 'OAK', 'TBR'],\n",
    "    2021: ['SFG', 'LAD', 'MIL', 'ATL', 'STL', 'TBR', 'HOU', 'CHW', 'BOS', 'NYY'],\n",
    "    2022: ['LAD', 'ATL', 'NYM', 'STL', 'SDP', 'PHI', 'HOU', 'NYY', 'CLE', 'SEA', 'TOR', 'TBR'],\n",
    "    2023: ['ATL', 'LAD', 'PHI', 'MIL', 'ARI', 'MIA', 'BAL', 'TBR', 'HOU', 'MIN', 'TEX', 'TOR']\n",
    "}\n",
    "\n",
    "# All the MLB team abbreviations\n",
    "ALL_TEAMS = ['ARI', 'ATL', 'BAL', 'BOS', 'CHC', 'CHW', 'CIN', 'CLE', 'COL', 'DET',\n",
    "             'HOU', 'KCR', 'LAA', 'LAD', 'MIA', 'MIL', 'MIN', 'NYM', 'NYY', 'OAK',\n",
    "             'PHI', 'PIT', 'SDP', 'SEA', 'SFG', 'STL', 'TBR', 'TEX', 'TOR', 'WSN']\n",
    "\n",
    "# Create playoff records for all teams in all seasons\n",
    "playoff_records = []\n",
    "\n",
    "#making the csv file in order of seasons, startin gfrom 2015\n",
    "for season in seasons:\n",
    "    playoff_teams = PLAYOFF_TEAMS[season]\n",
    "    print(f\"{season}: {len(playoff_teams)} playoff teams\")\n",
    "    \n",
    "    for team in ALL_TEAMS:\n",
    "        playoff_records.append({\n",
    "            'Season': season,\n",
    "            'Team': team,\n",
    "            'Made_Playoffs': 1 if team in playoff_teams else 0\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "playoff_df = pd.DataFrame(playoff_records)\n",
    "\n",
    "#ensuring the observations is the correct amount: 240\n",
    "print(f\"\\nTotal observations: {len(playoff_df)}\")\n",
    "#ensuring the playoff team count/observations is the correct amount: 84\n",
    "print(f\"Total playoff qualifications: {playoff_df['Made_Playoffs'].sum()}\")\n",
    "\n",
    "# Save playoff data\n",
    "playoff_df.to_csv('data/00-raw/standings.csv', index=False)\n",
    "#Confirm that the data is stored to the raw data folder\n",
    "print(\"Saved to: data/00-raw/standings.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the raw data, there was an absurd amount of columns, so we will only take what is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Cleaning Data\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Batting: 240 observations (0 duplicates removed)\n",
      "Pitching: 240 observations (0 duplicates removed)\n",
      "Standings: 240 observations (0 duplicates removed)\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Selecting Key Columns\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Batting columns: 15 selected\n",
      "  ['Season', 'Team', 'G', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'BB', 'SO', 'AVG', 'OBP', 'SLG', 'OPS']\n",
      "Pitching columns: 16 selected\n",
      "  ['Season', 'Team', 'W', 'L', 'ERA', 'G', 'GS', 'SV', 'IP', 'H', 'R', 'ER', 'HR', 'BB', 'SO', 'WHIP']\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning/Wrangling Section\n",
    "\n",
    "#Clean the data\n",
    "\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Cleaning Data\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Clean the batting data only\n",
    "if not batting_all.empty:\n",
    "    # Remove whitespace from columns and team names\n",
    "    batting_all.columns = batting_all.columns.str.strip()\n",
    "    if 'Team' in batting_all.columns:\n",
    "        batting_all['Team'] = batting_all['Team'].str.strip()\n",
    "    \n",
    "    # Remove duplicates if there are any (There shouldn't based on our manual checks)\n",
    "    original_len = len(batting_all)\n",
    "    # If there is a duplicate (There shouldn't) then keep the first\n",
    "    batting_all = batting_all.drop_duplicates(subset=['Season', 'Team'], keep='first')\n",
    "    print(f\"Batting: {len(batting_all)} observations ({original_len - len(batting_all)} duplicates removed)\")\n",
    "\n",
    "# Clean the pitching data\n",
    "if not pitching_all.empty:\n",
    "    # Remove whitespace\n",
    "    pitching_all.columns = pitching_all.columns.str.strip()\n",
    "    if 'Team' in pitching_all.columns:\n",
    "        pitching_all['Team'] = pitching_all['Team'].str.strip()\n",
    "    \n",
    "    # Remove any duplicates if they exist (There shouldn't based on manual checks)\n",
    "    original_len = len(pitching_all)\n",
    "    pitching_all = pitching_all.drop_duplicates(subset=['Season', 'Team'], keep='first')\n",
    "    #Compare the original to if any duplicates\n",
    "    print(f\"Pitching: {len(pitching_all)} observations ({original_len - len(pitching_all)} duplicates removed)\")\n",
    "\n",
    "# Clean playoff data\n",
    "if not playoff_df.empty:\n",
    "    playoff_df['Team'] = playoff_df['Team'].str.strip()\n",
    "    original_len = len(playoff_df)\n",
    "    playoff_df = playoff_df.drop_duplicates(subset=['Season', 'Team'], keep='first')\n",
    "    print(f\"Standings: {len(playoff_df)} observations ({original_len - len(playoff_df)} duplicates removed)\")\n",
    "\n",
    "########################################################\n",
    "#Finding Key Columns\n",
    "\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Selecting Key Columns\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Select batting columns and keep only what we need\n",
    "batting_cols = ['Season', 'Team', 'G', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'BB', 'SO', \n",
    "                'AVG', 'OBP', 'SLG', 'OPS']\n",
    "batting_cols = [col for col in batting_cols if col in batting_all.columns]\n",
    "batting_clean = batting_all[batting_cols].copy()\n",
    "\n",
    "#Confirm which ones we're keeping\n",
    "print(f\"Batting columns: {len(batting_cols)} selected\")\n",
    "print(f\"  {batting_cols}\")\n",
    "\n",
    "# Select pitching columns keep only what we need\n",
    "pitching_cols = ['Season', 'Team', 'W', 'L', 'ERA', 'G', 'GS', 'SV', 'IP', 'H', 'R', \n",
    "                 'ER', 'HR', 'BB', 'SO', 'WHIP']\n",
    "pitching_cols = [col for col in pitching_cols if col in pitching_all.columns]\n",
    "pitching_clean = pitching_all[pitching_cols].copy()\n",
    "\n",
    "#Confirm which ones we're keeping\n",
    "print(f\"Pitching columns: {len(pitching_cols)} selected\")\n",
    "print(f\"  {pitching_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Batting and Pitching DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Merging Batting and Pitching\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Merged dataset: 240 observations\n"
     ]
    }
   ],
   "source": [
    "# Merge the pitching and the hitting data\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Merging Batting and Pitching\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Rename columns to avoid conflicts\n",
    "# In batting: 'R' means runs scored\n",
    "# In pitching: 'R' means runs allowed\n",
    "pitching_clean = pitching_clean.rename(columns={\n",
    "    'G': 'G_pitch',\n",
    "    'R': 'RA',  # Runs allowed\n",
    "    'H': 'H_pitch',\n",
    "    'HR': 'HR_pitch',\n",
    "    'BB': 'BB_pitch',\n",
    "    'SO': 'SO_pitch'\n",
    "})\n",
    "\n",
    "# Merge on Season and Team\n",
    "merged = batting_clean.merge(\n",
    "    pitching_clean,\n",
    "    on=['Season', 'Team'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Should still be 240 because we are only adding variables, not new rows\n",
    "print(f\"Merged dataset: {len(merged)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Run Differential and Merge with Playoff Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Calculating Run Differential\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Calculated Run Differential Per Game\n",
      "  Mean (Should be 0): -0.000\n",
      "  Std:  0.810\n",
      "  Range: [-2.093, 2.062]\n",
      "\n",
      "Saved to: data/01-interim/batting_pitching_merged.csv\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Merging Playoff Qualification\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Final dataset: 240 observations\n",
      "\n",
      "Playoff breakdown:\n",
      "  Made playoffs: 84\n",
      "  Didn't make playoffs: 156\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Calculating Run Differential\")\n",
    "print(\"+\"*80)\n",
    "merged.head(10)\n",
    "if 'R' in merged.columns and 'RA' in merged.columns:\n",
    "    # Calculate run differential\n",
    "    merged['Run_Differential'] = merged['R'] - merged['RA']\n",
    "    \n",
    "    # Calculate per game\n",
    "    # USing GS because this is the total number of games in a season 162\n",
    "    if 'GS' in merged.columns:\n",
    "        merged['Run_Diff_Per_Game'] = merged['Run_Differential'] / merged['GS']\n",
    "        print(f\"Calculated Run Differential Per Game\")\n",
    "\n",
    "        #some summary statistics of the run differentials\n",
    "        print(f\"  Mean (Should be 0): {merged['Run_Diff_Per_Game'].mean():.3f}\")\n",
    "        print(f\"  Std:  {merged['Run_Diff_Per_Game'].std():.3f}\")\n",
    "        print(f\"  Range: [{merged['Run_Diff_Per_Game'].min():.3f}, {merged['Run_Diff_Per_Game'].max():.3f}]\")\n",
    "\n",
    "# Save interim merged data into the designated folder\n",
    "merged.to_csv('data/01-interim/batting_pitching_merged.csv', index=False)\n",
    "print(\"\\nSaved to: data/01-interim/batting_pitching_merged.csv\")\n",
    "\n",
    "######################################################\n",
    "# Merging with Playoff Data\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"+\"*80)\n",
    "print(\"Merging Playoff Qualification\")\n",
    "print(\"+\"*80)\n",
    "\n",
    "# Merge with playoff data\n",
    "final_df = merged.merge(\n",
    "    playoff_df,\n",
    "    on=['Season', 'Team'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill any missing playoff indicators with 0\n",
    "# Even though there shouldn't be any based on manual checks\n",
    "final_df['Made_Playoffs'] = final_df['Made_Playoffs'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Final dataset: {len(final_df)} observations\")\n",
    "print(f\"\\nPlayoff breakdown:\")\n",
    "print(f\"  Made playoffs: {final_df['Made_Playoffs'].sum()}\")\n",
    "print(f\"  Didn't make playoffs: {(final_df['Made_Playoffs'] == 0).sum()}\")\n",
    "\n",
    "\n",
    "#NOT UPDATED INTO THE CSV FILE YET\n",
    "# THAT IS FOR COMPLETELY CLEANED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cleaning\n",
      "Final clean dataset: 240 observations\n",
      "Saving Processed Data\n",
      "Saved to: data/02-processed/mlb_prediction_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Cleaning\")\n",
    "\n",
    "# Drop rows with missing key variables\n",
    "# Can change depending on what is needed for EDA\n",
    "key_vars = ['OPS', 'ERA', 'Run_Diff_Per_Game', 'Made_Playoffs']\n",
    "key_vars = [var for var in key_vars if var in final_df.columns]\n",
    "\n",
    "original_len = len(final_df)\n",
    "\n",
    "# Dropping data only if it is a part of the key variables and has a null value\n",
    "# None of them should have Nulls\n",
    "final_df = final_df.dropna(subset=key_vars)\n",
    "dropped = original_len - len(final_df)\n",
    "\n",
    "if dropped > 0:\n",
    "    print(f\"  Dropped {dropped} rows with missing key variables\")\n",
    "\n",
    "print(f\"Final clean dataset: {len(final_df)} observations\")\n",
    "\n",
    "# Save the Processed Data\n",
    "\n",
    "print(\"Saving Processed Data\")\n",
    "\n",
    "\n",
    "# Save final processed data\n",
    "final_df.to_csv('data/02-processed/mlb_prediction_dataset.csv', index=False)\n",
    "print(\"Saved to: data/02-processed/mlb_prediction_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: The players opt-in when signing with an MLB franchise, which is part of the MLB organization\n",
    "\n",
    " - [X] **A.2 Collection bias**: There are possible biases that occur from schedule strength, rule changes, playoff format changes, injuries, etc.. We compare across seasons and exclude 2020 to counter these. \n",
    " - [X] **A.3 Limit PII exposure**: When MLB players sign for their teams, they sign to be a part of the MLB rules, which includes rules of data collection.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: We will avoid using our model to make claims about players or individuals, since our analysis is team-level. We will also be careful about over-interpreting predictions because unmeasured factors like injuries, payroll, roster changes, and strength of schedule can affect outcomes. We will reduce misuse by clearly stating limitations and framing results as predictive, not causal.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: It is public and non-sensitive data. We stored it in the project repo with basic access control.\n",
    " - [X] **B.2 Right to be forgotten**:  Not applicable since no personal data is collected.\n",
    " - [X] **B.3 Data retention plan**: We would keep only what’s needed for the project and remove the features that are unnecessary along with the years we excluded. We won’t do unnecessary raw pulls.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: We will check our assumptions using baseball analytics sources and basic sanity checks.  \n",
    " - [X] **C.2 Dataset bias**: There aren't any biases because the data collected, is collected uniformly, throughout the whole league, and for every game played.\n",
    " - [X] **C.3 Honest representation**: We will report results honestly and avoid cherry-picking seasons or graphs.  \n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: We will only analyze team-level data and will not include any personal or identifying information. \n",
    " - [X] **C.5 Auditability**: Our code and workflow will be reproducible so others can rerun the same analysis.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Our features are performance stats, not proxies for protected traits.  \n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Fairness across protected groups is not directly relevant here, but we can still check if the model performs differently across leagues or divisions.\n",
    " - [X] **D.3 Metric selection**: We will use evaluation metrics like AUC and F1 so we do not rely only on accuracy.  \n",
    " - [X] **D.4 Explainability**: We will start with an interpretable model and explain how each metric affects playoff probability.\n",
    " - [X] **D.5 Communicate limitations**: We will clearly state limitations and avoid claiming the model proves causation.  \n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: If this were deployed, we would re-evaluate performance each season and after major league changes.  \n",
    " - [X] **E.2 Redress**: We would include clear disclaimers and review mistakes to improve the model over time.  \n",
    " - [X] **E.3 Roll back**: We would keep versions of the model so we can roll back if a new version performs worse.\n",
    " - [X] **E.4 Unintended use**: We will warn against unintended use, like treating predictions as guarantees or using them for gambling decisions. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Communication**\n",
    "\n",
    "Our primary method of communication will be  iMessage and Discord, with Gmail used as a backup.\n",
    "\n",
    "Team members are expected to respond to messages promptly if major work needs to be done on their part and deadlines are near, and team members should be notified of updates on the work that needs to be completed.\n",
    "The team will meet usually once per week on Mondays, meeting virtually or in-person, depending on what was discussed in the team group chat  to discuss progress, upcoming deadlines, and problems that have caused members to be “stuck”.\n",
    "\n",
    "**Collaboration & Decision-Making**\n",
    "\n",
    "We agree to maintain a respectful communication tone.\n",
    "\n",
    "Decisions will be made through a majority vote.\n",
    "\n",
    "If a team member disagrees with a decision, they are encouraged to voice their concerns and reason with the rest of the group as to why they think that way so all perspectives are considered before moving forward.\n",
    "\n",
    "**Work Distribution & Accountability**\n",
    "\n",
    "Tasks will be divided  based on strengths with rotation, and responsibilities will be tracked through Github and oral communication.\n",
    "All team members are expected to contribute to data exploration, analysis, coding, writing, and editing, even if they take lead roles in specific areas.\n",
    "If a team member anticipates difficulty meeting a deadline, they will notify the group at least 2 days in advance so the team can adjust responsibilities as needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/4 (Wed)  |  11:00 AM | Review COGS 108 project expectations and rubric; brainstorm possible topics and questions  | Finalize communication method; select final project topic; define research question and scope; assign background research tasks | \n",
    "| 2/12 (Thurs) |  3:15 PM |  Conduct background research; gather relevant literature | Synthesize prior work; refine hypothesis; identify variables and controls; discuss ideal dataset and ethical considerations | \n",
    "| 2/17 (Mon)| 5:30 PM  | Search for and evaluate potential datasets; begin proposal drafting  | Finalize dataset choice; discuss data limitations; refine methods; assign roles for wrangling, EDA, and analysis |\n",
    "| 2/24 (Mon) | 5:30 PM  | Import and clean data; complete initial data wrangling | Review data quality; address missing values and inconsistencies; finalize EDA plan  |\n",
    "| 3/3 (Mon)| 5:30 PM  | Complete EDA and preliminary visualizations | Interpret EDA results; refine analysis approach; identify potential modeling or statistical methods |\n",
    "| 3/10 (Mon) | 5:30 PM  | Perform full analysis; draft results and discussion sections | Review analysis outputs; refine visualizations; discuss limitations and ethical implications |\n",
    "| 3/17 (Mon)  | 5:30 PM  | Complete full project draft; finalize figures, documentation and complete the final VIDEO | Final peer review; polish writing; ensure reproducibility and readiness for submission | \n",
    "| 3/18 (Tue)  | Before 11:59 PM  | NA | Submit Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
